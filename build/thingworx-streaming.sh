#!/bin/bash
cd ${TWB_BASE}/config/
kinit svc-ra-bicoeloaddev@RA-INT.COM -k -t svc-ra-bicoeloaddev.keytab
export HADOOP_CONF_DIR=/etc/hadoop/conf:/etc/hive/conf
nohup spark-submit --master yarn-cluster --name dev_thingwox_streaming --keytab "svc-ra-bicoeloaddev.keytab" --principal "svc-ra-bicoeloaddev@RA-INT.COM" --conf "spark.streaming.kafka.maxRatePerPartition=1" --conf "spark.dynamicAllocation.enabled=false" --num-executors 3 --driver-memory 5g --executor-memory 3g --conf "spark.streaming.unpersist=true" --conf "spark.executor.heartbeatInterval=20s" --conf "spark.streaming.kafka.maxRetries=5" --conf "spark.streaming.backpressure.enabled=true" --conf "spark.executor.extraJavaOptions=-XX:+UseG1GC -Djava.security.krb5.conf=/etc/krb5.conf" --conf "spark.driver.extraJavaOptions=-XX:+UseG1GC -Djava.security.krb5.conf=/etc/krb5.conf" --conf spark.yarn.stagingDir=hdfs:///tmp/spark/ --files "thingworx-streaming.properties" --conf spark.yarn.maxAppAttempts=4 --conf spark.yarn.max.executor.failures=24 --conf spark.task.maxFailures=8 --conf spark.hadoop.fs.hdfs.impl.disable.cache=true ${TWB_BASE}/build/thingwox-streaming-0.0.1-SNAPSHOT.jar thingworx-streaming.properties > thingworx-streaming.log 2>&1 & echo $! > thingworx-streaming.properties.pid
